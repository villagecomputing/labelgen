{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NAICS Code Generation\n",
    "\n",
    "This notebook demonstrates how to use SuperPipe to generate North American Industry Classification System (NAICS) codes for businesses based on name and address.\n",
    "\n",
    "We are provided with a list of business names and addresses, for example\n",
    "\n",
    "```\n",
    "{\n",
    "  \"name\": \"\",\n",
    "  \"street\": \"\",\n",
    "  \"city\": \"\",\n",
    "  \"state\": \"\",\n",
    "  \"zip\": {}\n",
    "}\n",
    "```\n",
    "\n",
    "The objective is to accurately assign a NAICS code to each business, which categorizes it into a specific industry. For example, the NAICS code for the above business might be\n",
    "\n",
    "`311811 - Retail Bakeries`\n",
    "\n",
    "The challenge is to correctly generate the NAICS code for each business, considering the vast array of industries covered by the NAICS system.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Approach\n",
    "\n",
    "We'll implement the following multi-step approach:\n",
    "\n",
    "1. Do a google search with the company's name and address\n",
    "\n",
    "2. Feed the name and the search results from Step 1 into an LLM and ask it for the 3 most likely NAICS codes\n",
    "\n",
    "3. Feed the name, search results and the 3 most likely NAICS codes from Step 2 into an LLM and ask it for the most likely NAICS code along with its reasoning.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import libraries, and load the data and the taxonomy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/bh/hwln9nhn6tb990j17wgs638r0000gn/T/ipykernel_42665/1849040241.py:1: DeprecationWarning: \n",
      "Pyarrow will become a required dependency of pandas in the next major release of pandas (pandas 3.0),\n",
      "(to allow more performant data types, such as the Arrow string type, and better interoperability with other libraries)\n",
      "but was not found to be installed on your system.\n",
      "If this would cause problems for you,\n",
      "please provide us feedback at https://github.com/pandas-dev/pandas/issues/54466\n",
      "        \n",
      "  import pandas as pd\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "from pydantic import BaseModel, Field\n",
    "from typing import List\n",
    "from superpipe import *\n",
    "\n",
    "# df = pd.read_csv('./data.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Defining the Pipeline using SuperPipe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's define the first step of the pipeline which uses a Google SERP library to search for the `description` field on the input object.\n",
    "\n",
    "We do this by using SuperPipe's built-in `SERPEnrichmentStep`. You could also easily build your own using a `CustomStep` instead."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def shorten(x):\n",
    "    short = []\n",
    "    kgi = json.loads(x).get('knowledgeGraph')\n",
    "    if kgi is None:\n",
    "        short.append(kgi)\n",
    "    else:\n",
    "        kg = {'title': kgi.get('title'), 'type': kgi.get(\n",
    "            'type'), 'description': kgi.get('description')},\n",
    "        short.append(kg)\n",
    "    y = json.loads(x).get('organic')\n",
    "    if y is None:\n",
    "        return None\n",
    "    for o in y[:3]:\n",
    "        short.append({\n",
    "            'title': o['title'],\n",
    "            'snippet': o['snippet'],\n",
    "            'link': o['link']\n",
    "        })\n",
    "    return short\n",
    "\n",
    "\n",
    "def serp_prompt(row):\n",
    "    name = row['name']\n",
    "    street = row['address']['street']\n",
    "    city = row['address']['city']\n",
    "    state = row['address']['state']\n",
    "    zip = row['address']['zip']\n",
    "    return f\"Review for {name} located at {street} {city} {state} {str(zip)}\"\n",
    "\n",
    "\n",
    "serp_step = steps.SERPEnrichmentStep(\n",
    "  prompt=serp_prompt,\n",
    "  postprocess=shorten,\n",
    "  name=\"serp\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The second step of the pipeline takes the business name and the search results and feeds them into an LLM to get the 3 most likely NAICS codes. We create this step using `LLMStep`.\n",
    "\n",
    "An `LLMStep` instance takes a Pydantic model and a prompt generator function as arguments. The pydantic model specifies the output structure (remember every `LLMStep` creates structured output). The prompt generator function defines how to generate a prompt from the input data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def top3_codes_prompt(row):\n",
    "    return f\"\"\"You are given a business name and a list of google search results about a company.\n",
    "    Return an array of the top 3 most like NAICS business codes this company falls into. Only use codes in the 2022 taxonomy.\n",
    "\n",
    "    Company name: {row['name']}\n",
    "    Search results:\n",
    "    {row['serp']}\n",
    "    \"\"\"\n",
    "\n",
    "\n",
    "class Top3Codes(BaseModel):\n",
    "    top3_codes: List[int] = Field(\n",
    "        description=\"The top 3 most likely NAICS codes\")\n",
    "\n",
    "\n",
    "top3_codes_step = steps.LLMStep(\n",
    "  model=models.gpt4,\n",
    "  prompt=top3_codes_prompt,\n",
    "  out_schema=Top3Codes,\n",
    "  name=\"top3_codes\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The third step the business name, search results and 3 most likely NAICS codes into an LLM to get the most likely NAICS code and the thinking behind it. Again, we create this step using `LLMStep`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def top_code_prompt(row): return f\"\"\"\n",
    "You are given a business name and a list of google search results about a company.\n",
    "You are given 3 possible NAICS codes it could be -- pick the best one and explain your thinking.\n",
    "\n",
    "Company name: {row['name']}\n",
    "NAICS options: {row['top3_codes']}\n",
    "Search results:\n",
    "{row['serp']}\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "class TopCode(BaseModel):\n",
    "    result: int = Field(description=\"The best NAICS code\")\n",
    "    thinking: str = Field(\n",
    "        description=\"The thought process for why this is the best NAICS code\")\n",
    "\n",
    "\n",
    "top1_code_step = steps.LLMStep(\n",
    "  model=models.gpt4,\n",
    "  prompt=top_code_prompt,\n",
    "  out_schema=TopCode,\n",
    "  name=\"top1_code\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We're done defining the steps. Finally, we define an evaluation function - a simple string comparison against the ground truth column which was present in the dataset. Then we define a `Pipeline` and run it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate = lambda row: row['result'] == row['NAICS']\n",
    "\n",
    "naics_coder = pipeline.Pipeline(\n",
    "  steps=[\n",
    "    serp_step,\n",
    "    top3_codes_step,\n",
    "    top1_code_step], \n",
    "  evaluation_fn=evaluate)\n",
    "\n",
    "naics_coder.apply(df)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "labelkit--WQojwT2-py3.10",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
